{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf8ab32",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In this section, we implement a complete RAG pipeline for answering questions based on a given context. Using the LangChain library, we'll walk through the entire process—from retrieving relevant context to generating accurate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc73147",
   "metadata": {},
   "source": [
    "So far, we have done -\n",
    "1. **Indexing**: Organize the raw documents into a structured format suitable for processing, such as splitting them into chunks or passages for more efficient retrieval.\n",
    "\n",
    "2. **Embedding**: Convert each text chunk into a dense vector representation using a pre-trained embedding model. These embeddings capture the semantic meaning of the content.\n",
    "\n",
    "3. **Vector Store**: Store the embeddings in a vector database (Qdrant in our case), allowing fast and scalable similarity search across the document collection.\n",
    "\n",
    "4. **Retrieval and Generation**: In this notebook, given a user query, retrieve the most relevant document chunks from the vector store and feed them into a language model (EVE) to generate a context-aware, accurate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62191c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinorohit/pischool/eve-rag/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embeddings model\n",
    "model_name = \"nasa-impact/nasa-smd-ibm-st-v2\"\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,  encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b613d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is tropomi?\"\n",
    "query_vector = embedder.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f8624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# get your keys from the qdrant UI\n",
    "QDRANT_API_KEY = os.environ['QDRANT_API_KEY']\n",
    "QDRANT_URL = os.environ['QDRANT_URL']\n",
    "\n",
    "collection_name = \"ingestion_demo\"\n",
    "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bef381",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=1  # number of similar results you want\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9723960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval score: 0.7168092\n",
      "retrieved chunk: TROPOMI (Tropospheric Monitoring Instrument) is a cutting-edge satellite instrument aboard the European Copernicus Sentinel-5 Precursor (S5P) satellite, launched in October 2017.\" \n",
      "            It plays an essential role in gathering data that helps scientists to better understand atmospheric processes and environmental changes. \n",
      "            TROPOMI’s high-resolution data contributes to global efforts in monitoring air quality, tracking climate trends, and protecting the ozone layer, \n",
      "            making it a key tool for advancing environmental science and policy worldwide.\n"
     ]
    }
   ],
   "source": [
    "for result in results.points:\n",
    "    print(f\"retrieval score: {result.score}\")\n",
    "    print(f\"retrieved chunk: {result.payload['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ba6a3c",
   "metadata": {},
   "source": [
    "## Generation\n",
    "\n",
    "Once the relevant context is retrieved, it is passed to an LLM to generate a coherent and informed response based on both the query and the retrieved context.\n",
    "\n",
    "This approach ensures that the generated answers are grounded in the source documents, improving accuracy and reducing hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a434ae1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen3-0.6B\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b489e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "system_message = '''You are an expert assistant that answers questions about different topics.\n",
    "If you don't know the answer, just say \"I don't know.\" Don't try to make up an answer.\n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "Do not use any prior knowledge.'''\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(\n",
    "        content=f\"Context: {result.payload['content']} Question: {query}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac9f6a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an expert assistant that answers questions about different topics.\n",
      "If you don't know the answer, just say \"I don't know.\" Don't try to make up an answer.\n",
      "Use only the following pieces of context to answer the question at the end.\n",
      "Do not use any prior knowledge.<|im_end|>\n",
      "<|im_start|>user\n",
      "Context: TROPOMI (Tropospheric Monitoring Instrument) is a cutting-edge satellite instrument aboard the European Copernicus Sentinel-5 Precursor (S5P) satellite, launched in October 2017.\" \n",
      "            It plays an essential role in gathering data that helps scientists to better understand atmospheric processes and environmental changes. \n",
      "            TROPOMI’s high-resolution data contributes to global efforts in monitoring air quality, tracking climate trends, and protecting the ozone layer, \n",
      "            making it a key tool for advancing environmental science and policy worldwide. Question: what is tropomi?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, let's see. The user is asking what TROPOMI is. The context provided mentions that TROPOMI is a satellite instrument from the European Copernicus Sentinel-5P satellite, launched in October 2017. It's used to gather data for understanding atmospheric processes and environmental changes. Also, it contributes to monitoring air quality, climate trends, and ozone layer protection.\n",
      "\n",
      "So, the question is straightforward. The answer should be that TROPOMI is the instrument on the Sentinel-5P satellite. I need to make sure not to include any other information from the context beyond what's provided. Since the context doesn't mention anything else, I can confidently state that TROPOMI is the instrument used by the satellite.\n",
      "</think>\n",
      "\n",
      "TROPOMI is a cutting-edge satellite instrument aboard the European Copernicus Sentinel-5P satellite, launched in October 2017. It plays a key role in gathering high-resolution data to help scientists understand atmospheric processes and environmental changes.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46619475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eve-rag (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
