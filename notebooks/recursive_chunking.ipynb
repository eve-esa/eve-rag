{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b9c8da",
   "metadata": {},
   "source": [
    "## What is Text Chunking?\n",
    "\n",
    "**Text chunking** is the process of breaking down large documents into smaller, manageable pieces called \"chunks\". \n",
    "\n",
    "In RAG (Retrieval-Augmented Generation) systems, chunking solves several critical problems:\n",
    "\n",
    "### 1. **Context Window Limitations**\n",
    "- Language models (like GPT) can only process a limited amount of text at once\n",
    "- Example: If a model can handle 4,000 tokens but your document is 10,000 tokens, you need to split it\n",
    "\n",
    "### 2. **Better Search & Retrieval**\n",
    "- Smaller chunks allow for more precise searching\n",
    "- Instead of finding a whole document, users can find the specific paragraph they need\n",
    "\n",
    "### 3. **Improved Relevance**\n",
    "- When a user asks a question, the system can retrieve the most relevant chunk(s) instead of the entire document\n",
    "- This leads to more focused and accurate answers\n",
    "\n",
    "\n",
    "## Key Chunking Concepts\n",
    "\n",
    "**Chunk Size**: How many words/tokens per chunk\n",
    "- Too small → Lose context\n",
    "- Too large → Poor search precision\n",
    "\n",
    "**Chunk Overlap**: How much chunks should overlap\n",
    "- Prevents cutting off important information at chunk boundaries\n",
    "- Helps maintain context between adjacent chunks\n",
    "\n",
    "**Preserving Structure**: Keeping paragraphs, headings, and formatting intact\n",
    "- Maintains readability and context\n",
    "- Helps with better understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90d96a",
   "metadata": {},
   "source": [
    "# Recursive Chunking\n",
    "\n",
    "## What is Recursive Chunking?\n",
    "\n",
    "Instead of randomly cutting text, recursive chunking follows a **hierarchical approach**:\n",
    "\n",
    "1. **First**: Try to split by paragraphs (keeps ideas together)\n",
    "2. **Then**: If paragraphs are still too big, split by sentences\n",
    "3. **Finally**: If sentences are too big, split by words\n",
    "\n",
    "This ensures we **preserve meaning and structure** as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ea2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from langchain_text_splitters.base import TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e78c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_paragraphs(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into paragraphs while preserving formatting.\n",
    "    - Takes a big block of text\n",
    "    - Breaks it into separate paragraphs\n",
    "    - Keeps the original formatting (spaces, line breaks)\n",
    "    - Removes empty paragraphs\n",
    "    \"\"\"\n",
    "    \n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "    return [p for p in paragraphs if p.strip()]\n",
    "\n",
    "\n",
    "def _split_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into sentences while preserving original formatting.\n",
    "    \n",
    "    - Takes a paragraph or block of text\n",
    "    - Breaks it into individual sentences\n",
    "    - Keeps the original spacing and punctuation\n",
    "    - Preserves how the text was originally formatted\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    pattern = r'(?<=[.!?])(\\s+)'\n",
    "    parts = re.split(pattern, text)\n",
    "    \n",
    "    sentences = []\n",
    "    for i in range(0, len(parts), 2):\n",
    "        sentence = parts[i] \n",
    "        \n",
    "        if i + 1 < len(parts):\n",
    "            sentence += parts[i + 1]  \n",
    "            \n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return [s for s in sentences if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96090f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Original text:\n",
      "This is the first paragraph.\n",
      "\n",
      "This is the second paragraph with some text.\n",
      "\n",
      "\n",
      "This is the third paragraph after extra empty lines.\n",
      "\n",
      "Split into paragraphs:\n",
      "Paragraph 1: This is the first paragraph.\n",
      "Paragraph 2: This is the second paragraph with some text.\n",
      "Paragraph 3: This is the third paragraph after extra empty lines.\n",
      "\n",
      "Original sentences:\n",
      "Hello world! How are you today? I'm doing great.  Let's learn about chunking!\n",
      "\n",
      "Split into sentences:\n",
      "Sentence 1: Hello world! \n",
      "Sentence 2: How are you today? \n",
      "Sentence 3: I'm doing great.  \n",
      "Sentence 4: Let's learn about chunking!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "\n",
    "# Test paragraph splitting\n",
    "test_text = \"\"\"This is the first paragraph.\n",
    "\n",
    "This is the second paragraph with some text.\n",
    "\n",
    "\n",
    "This is the third paragraph after extra empty lines.\"\"\"\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(test_text)\n",
    "\n",
    "print(\"\\nSplit into paragraphs:\")\n",
    "paragraphs = _split_paragraphs(test_text)\n",
    "for i, para in enumerate(paragraphs, 1):\n",
    "    print(f\"Paragraph {i}: {para}\")\n",
    "\n",
    "test_sentence = \"Hello world! How are you today? I'm doing great.  Let's learn about chunking!\"\n",
    "\n",
    "print(f\"\\nOriginal sentences:\")\n",
    "print(test_sentence)\n",
    "\n",
    "print(f\"\\nSplit into sentences:\")\n",
    "sentences = _split_sentences(test_sentence)\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"Sentence {i}: {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd143a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveMarkdownSplitter(TextSplitter):\n",
    "    \"\"\"\n",
    "    Split text into smaller chunks while preserving meaning and structure\n",
    "    \n",
    "    This class implements our recursive chunking strategy.\n",
    "    \n",
    "    - Preserves Markdown formatting (headings, code blocks, etc.)\n",
    "    - Follows natural text boundaries (paragraphs → sentences → words)\n",
    "    - Configurable chunk size and overlap\n",
    "    - Maintains original spacing and formatting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 100, chunk_overlap: int = 0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chunk_size (int): Maximum number of words per chunk (default: 100)\n",
    "            chunk_overlap (int): How many words should overlap between chunks (default: 0)\n",
    "        \"\"\"\n",
    "        super().__init__(keep_separator=True)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        \n",
    "        print(f\"   RecursiveMarkdownSplitter initialized!\")\n",
    "        print(f\"   Chunk size: {chunk_size} words\")\n",
    "        print(f\"   Chunk overlap: {chunk_overlap} words\")\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        return self._recursive_split(text)\n",
    "    \n",
    "    def chunk(self, text: str) -> List[str]:\n",
    "        return self._recursive_split(text)\n",
    "\n",
    "    def _count_words(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        This is a simple word counter. We split by spaces and count the results.\n",
    "        \"\"\"\n",
    "        return len(text.split())\n",
    "\n",
    "    def _recursive_split(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        This method implements our hierarchical splitting strategy:\n",
    "        \n",
    "        1. Check if text is already small enough\n",
    "        2. Try splitting by paragraphs first\n",
    "        3. If paragraphs are too big, try sentences  \n",
    "        4. If sentences are too big, split by words\n",
    "        \"\"\"\n",
    "\n",
    "        if self._count_words(text) <= self.chunk_size:\n",
    "            print(f\"text is small enough ({self._count_words(text)} words): Using as one chunk\")\n",
    "            return [text]\n",
    "\n",
    "        \n",
    "        paragraphs = _split_paragraphs(text)\n",
    "        print(f\"Found {len(paragraphs)} paragraphs\")\n",
    "        \n",
    "        if len(paragraphs) > 1:\n",
    "            chunks = []\n",
    "            current = \"\"\n",
    "            \n",
    "            for p in paragraphs:\n",
    "                test_text = current + (\"\\n\\n\" if current else \"\") + p\n",
    "                \n",
    "                if self._count_words(test_text) <= self.chunk_size or not current:\n",
    "                    current += (\"\\n\\n\" if current else \"\") + p\n",
    "                else:\n",
    "                    chunks.extend(self._recursive_split(current))\n",
    "                    current = p  # Start new chunk with this paragraph\n",
    "            \n",
    "            if current:\n",
    "                chunks.extend(self._recursive_split(current))\n",
    "                \n",
    "            print(f\"Paragraph split complete: {len(chunks)} chunks created\")\n",
    "            return chunks\n",
    "\n",
    "        sentences = _split_sentences(text)\n",
    "        print(f\" Found {len(sentences)} sentences\")\n",
    "        \n",
    "        if len(sentences) > 1:\n",
    "            chunks = []\n",
    "            current = \"\"\n",
    "            \n",
    "            for s in sentences:\n",
    "                if self._count_words(current + s) <= self.chunk_size or not current:\n",
    "                    current += s\n",
    "                else:\n",
    "                    chunks.append(current)\n",
    "                    current = s \n",
    "            \n",
    "            if current:\n",
    "                chunks.append(current)\n",
    "                \n",
    "            print(f\"Sentence split complete: {len(chunks)} chunks created\")\n",
    "            return chunks\n",
    "\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(words):\n",
    "            end = start + self.chunk_size\n",
    "            chunk_text = \" \".join(words[start:end])\n",
    "            chunks.append(chunk_text)\n",
    "            \n",
    "            if self.chunk_overlap > 0:\n",
    "                start = end - self.chunk_overlap\n",
    "            else:\n",
    "                start = end\n",
    "                \n",
    "        print(f\"Word split complete: {len(chunks)} chunks created\")\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534cb43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "Testing with chunk size: 15 words\n",
      "----------------------------------------\n",
      "   RecursiveMarkdownSplitter initialized!\n",
      "   Chunk size: 15 words\n",
      "   Chunk overlap: 0 words\n",
      "Found 6 paragraphs\n",
      "text is small enough (3 words): Using as one chunk\n",
      "Found 1 paragraphs\n",
      " Found 2 sentences\n",
      "Sentence split complete: 2 chunks created\n",
      "Found 1 paragraphs\n",
      " Found 2 sentences\n",
      "Sentence split complete: 2 chunks created\n",
      "text is small enough (10 words): Using as one chunk\n",
      "text is small enough (13 words): Using as one chunk\n",
      "Paragraph split complete: 7 chunks created\n",
      "\n",
      "Results: 7 chunks created\n",
      "\n",
      "--- Chunk 1 (3 words) ---\n",
      "Content:\n",
      "\n",
      "# Example Document\n",
      "\n",
      "--- Chunk 2 (12 words) ---\n",
      "Content:\n",
      "This is a short example demonstrating how the Recursive Markdown\n",
      "Splitter works. \n",
      "\n",
      "--- Chunk 3 (8 words) ---\n",
      "Content:\n",
      "It keeps paragraphs and sentence spacing in place.\n",
      "\n",
      "--- Chunk 4 (8 words) ---\n",
      "Content:\n",
      "Here is another paragraph to force paragraph-level splitting. \n",
      "\n",
      "--- Chunk 5 (18 words) ---\n",
      "Content:\n",
      "This paragraph is intentionally longer to show how the chunker handles content that exceeds the chunk size limit.\n",
      "\n",
      "--- Chunk 6 (10 words) ---\n",
      "Content:\n",
      "## Code Example\n",
      "\n",
      "```python\n",
      "def hello_world():\n",
      "    print(\"Hello, chunking world!\")\n",
      "```\n",
      "\n",
      "--- Chunk 7 (13 words) ---\n",
      "Content:\n",
      "This demonstrates that code blocks and formatting are preserved properly in our chunks.\n",
      "\n",
      "\n",
      "Testing with chunk size: 25 words\n",
      "----------------------------------------\n",
      "   RecursiveMarkdownSplitter initialized!\n",
      "   Chunk size: 25 words\n",
      "   Chunk overlap: 0 words\n",
      "Found 6 paragraphs\n",
      "text is small enough (23 words): Using as one chunk\n",
      "Found 1 paragraphs\n",
      " Found 2 sentences\n",
      "Sentence split complete: 2 chunks created\n",
      "text is small enough (23 words): Using as one chunk\n",
      "Paragraph split complete: 4 chunks created\n",
      "\n",
      "Results: 4 chunks created\n",
      "\n",
      "--- Chunk 1 (23 words) ---\n",
      "Content:\n",
      "\n",
      "# Example Document\n",
      "\n",
      "This is a short example demonstrating how the Recursive Markdown\n",
      "Splitter works. It keeps paragraphs and sentence spacing in place.\n",
      "\n",
      "--- Chunk 2 (8 words) ---\n",
      "Content:\n",
      "Here is another paragraph to force paragraph-level splitting. \n",
      "\n",
      "--- Chunk 3 (18 words) ---\n",
      "Content:\n",
      "This paragraph is intentionally longer to show how the chunker handles content that exceeds the chunk size limit.\n",
      "\n",
      "--- Chunk 4 (23 words) ---\n",
      "Content:\n",
      "## Code Example\n",
      "\n",
      "```python\n",
      "def hello_world():\n",
      "    print(\"Hello, chunking world!\")\n",
      "```\n",
      "\n",
      "This demonstrates that code blocks and formatting are preserved properly in our chunks.\n",
      "\n",
      "\n",
      "Testing with chunk size: 50 words\n",
      "----------------------------------------\n",
      "   RecursiveMarkdownSplitter initialized!\n",
      "   Chunk size: 50 words\n",
      "   Chunk overlap: 0 words\n",
      "Found 6 paragraphs\n",
      "text is small enough (49 words): Using as one chunk\n",
      "text is small enough (23 words): Using as one chunk\n",
      "Paragraph split complete: 2 chunks created\n",
      "\n",
      "Results: 2 chunks created\n",
      "\n",
      "--- Chunk 1 (49 words) ---\n",
      "Content:\n",
      "\n",
      "# Example Document\n",
      "\n",
      "This is a short example demonstrating how the Recursive Markdown\n",
      "Splitter works. It keeps paragraphs and sentence spacing in place.\n",
      "\n",
      "Here is another paragraph to force paragraph-level splitting. This paragraph is intentionally longer to show how the chunker handles content that exceeds the chunk size limit.\n",
      "\n",
      "--- Chunk 2 (23 words) ---\n",
      "Content:\n",
      "## Code Example\n",
      "\n",
      "```python\n",
      "def hello_world():\n",
      "    print(\"Hello, chunking world!\")\n",
      "```\n",
      "\n",
      "This demonstrates that code blocks and formatting are preserved properly in our chunks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"\n",
    "# Example Document\n",
    "\n",
    "This is a short example demonstrating how the Recursive Markdown\n",
    "Splitter works. It keeps paragraphs and sentence spacing in place.\n",
    "\n",
    "Here is another paragraph to force paragraph-level splitting. This paragraph is intentionally longer to show how the chunker handles content that exceeds the chunk size limit.\n",
    "\n",
    "## Code Example\n",
    "\n",
    "```python\n",
    "def hello_world():\n",
    "    print(\"Hello, chunking world!\")\n",
    "```\n",
    "\n",
    "This demonstrates that code blocks and formatting are preserved properly in our chunks.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# testest with different chunk sizes to see the behavior\n",
    "chunk_sizes = [15, 25, 50]\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    print(f\"\\nTesting with chunk size: {size} words\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    splitter = RecursiveMarkdownSplitter(chunk_size=size)\n",
    "    \n",
    "    chunks = splitter.chunk(sample)\n",
    "    \n",
    "    print(f\"\\nResults: {len(chunks)} chunks created\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        word_count = splitter._count_words(chunk)\n",
    "        print(f\"\\n--- Chunk {i} ({word_count} words) ---\")\n",
    "        print(\"Content:\")\n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eve-rag (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
